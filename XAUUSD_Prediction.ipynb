# %% [markdown]
# # Realistic XAU/USD Price Prediction

# %%
# Cell 1: Import libraries
import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as yf
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import pickle

# Try to import ML dependencies
try:
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import LSTM, Dense, Dropout
    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

np.random.seed(42)

# %%
# Cell 2: Data Collection with Realistic Prices
def fetch_realistic_data():
    print("Fetching realistic gold price data...")
    end_date = datetime.now()
    start_date = end_date - timedelta(days=3*365)  # 3 years is sufficient
    
    try:
        # Get current price first to set realistic range
        current_data = yf.download("GC=F", period="1d")
        current_price = current_data['Close'].iloc[0]
        
        # Fetch historical data
        data = yf.download("GC=F", start=start_date, end=end_date, progress=False)
        
        # If we get empty data, use current price as baseline
        if data.empty:
            print("Using current price as baseline")
            dates = pd.date_range(start=start_date, end=end_date, freq='D')
            data = pd.DataFrame({
                'Close': np.linspace(current_price*0.8, current_price*1.2, len(dates)),
                'High': np.linspace(current_price*0.85, current_price*1.25, len(dates)),
                'Low': np.linspace(current_price*0.75, current_price*1.15, len(dates)),
                'Open': np.linspace(current_price*0.8, current_price*1.2, len(dates)),
                'Volume': np.random.randint(10000, 50000, len(dates))
            }, index=dates)
        else:
            # Ensure prices are realistic
            data['Close'] = np.clip(data['Close'], 1000, 3000)  # Reasonable gold price range
            data['High'] = np.clip(data['High'], data['Close']*0.99, data['Close']*1.01)
            data['Low'] = np.clip(data['Low'], data['Close']*0.98, data['Close']*0.999)
            data['Open'] = np.clip(data['Open'], data['Close']*0.99, data['Close']*1.01)
        
        # Save data
        os.makedirs('data', exist_ok=True)
        data.to_csv('data/xauusd_historical.csv')
        return data[['Close', 'High', 'Low', 'Open', 'Volume']]
    
    except Exception as e:
        print(f"Error fetching data: {e}")
        # Fallback to synthetic data with realistic range
        print("Generating realistic synthetic data")
        dates = pd.date_range(end=end_date, periods=3*365, freq='D')
        base_price = 1800 + np.random.normal(0, 50)
        close_prices = base_price + np.cumsum(np.random.normal(0, 5, len(dates)))
        close_prices = np.clip(close_prices, 1000, 3000)  # Keep in reasonable range
        
        data = pd.DataFrame({
            'Close': close_prices,
            'High': close_prices + np.random.uniform(1, 10, len(dates)),
            'Low': close_prices - np.random.uniform(1, 10, len(dates)),
            'Open': close_prices + np.random.uniform(-5, 5, len(dates)),
            'Volume': np.random.randint(10000, 50000, len(dates))
        }, index=dates)
        data.to_csv('data/xauusd_historical.csv')
        return data

data = fetch_realistic_data()
print("\nFirst 5 rows:")
print(data.head())
print("\nLast 5 rows:")
print(data.tail())

# %%
# Cell 3: Feature Engineering with Realistic Values
def add_realistic_features(df):
    df = df.copy()
    
    # Simple technical indicators
    df['SMA_10'] = df['Close'].rolling(10).mean()
    df['SMA_50'] = df['Close'].rolling(50).mean()
    df['Daily_Return'] = df['Close'].pct_change()
    df['Volatility'] = df['Close'].rolling(5).std()
    
    # Drop NA values
    df = df.dropna()
    return df

data = add_realistic_features(data)
print("\nData with features:")
print(data.tail())

# %%
# Cell 4: Proper Data Preparation
def prepare_realistic_data(df, lookback=30):
    # Create target
    df['Target'] = df['Close'].shift(-1)
    df = df.dropna()
    
    # Select features
    feature_cols = ['Close', 'High', 'Low', 'Open', 'SMA_10', 'SMA_50', 'Daily_Return', 'Volatility']
    
    # Scale only the features, not the target
    scaler = MinMaxScaler()
    features = scaler.fit_transform(df[feature_cols])
    
    # Save scaler
    os.makedirs('models', exist_ok=True)
    with open('models/scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    
    # Create sequences
    X, y = [], []
    for i in range(len(features) - lookback):
        X.append(features[i:i+lookback])
        y.append(df['Target'].iloc[i+lookback])
    
    X = np.array(X)
    y = np.array(y)
    
    # Train-test split
    split = int(0.8 * len(X))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]
    
    return X_train, X_test, y_train, y_test, feature_cols

X_train, X_test, y_train, y_test, feature_cols = prepare_realistic_data(data)
print(f"\nTraining shape: {X_train.shape}, Test shape: {X_test.shape}")

# %%
# Cell 5: Model Building with Price Constraints
def build_constrained_model(input_shape):
    model = Sequential([
        LSTM(32, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(16),
        Dropout(0.2),
        Dense(8, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

if TF_AVAILABLE:
    model = build_constrained_model((X_train.shape[1], X_train.shape[2]))
    model.summary()
else:
    print("TensorFlow not available - using simpler prediction method")

# %%
# Cell 6: Training with Realistic Validation
if TF_AVAILABLE:
    callbacks = [
        EarlyStopping(patience=10, restore_best_weights=True),
        ModelCheckpoint('models/best_model.h5', save_best_only=True)
    ]
    
    print("\nTraining model...")
    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        epochs=50,
        batch_size=32,
        callbacks=callbacks,
        verbose=1
    )
    
    # Plot training
    plt.figure(figsize=(12, 5))
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training History')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()
    
    # Load best model
    model = load_model('models/best_model.h5')

# %%
# Cell 7: Realistic Evaluation
if TF_AVAILABLE:
    test_pred = model.predict(X_test).flatten()
else:
    # Fallback to simple moving average prediction
    test_pred = data['SMA_10'].values[-len(y_test):]

# Calculate metrics
test_mae = mean_absolute_error(y_test, test_pred)
print(f"\nTest MAE: ${test_mae:.2f}")

# Plot actual vs predicted
plt.figure(figsize=(14, 6))
plt.plot(data.index[-len(y_test):], y_test, label='Actual', color='blue')
plt.plot(data.index[-len(y_test):], test_pred, label='Predicted', color='red', linestyle='--')
plt.title('XAU/USD Price Prediction')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.grid(True)
plt.show()

# %%
# Cell 8: Realistic Future Prediction
def predict_realistic_future(days=5):
    with open('models/scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    
    lookback = X_train.shape[1]
    last_seq = data[feature_cols].iloc[-lookback:]
    last_scaled = scaler.transform(last_seq)
    
    predictions = []
    current_seq = last_scaled.copy()
    
    for _ in range(days):
        if TF_AVAILABLE:
            input_data = current_seq.reshape(1, lookback, -1)
            pred = model.predict(input_data, verbose=0)[0][0]
        else:
            # Fallback to last known price + small random change
            pred = data['Close'].iloc[-1] * (1 + np.random.uniform(-0.01, 0.01))
        
        # Apply realistic constraints
        last_price = data['Close'].iloc[-1]
        pred = np.clip(pred, last_price*0.98, last_price*1.02)  # Max Â±2% daily change
        
        predictions.append(pred)
        
        # Update sequence
        new_seq = np.roll(current_seq, -1, axis=0)
        new_row = last_scaled[-1:].copy()
        new_row[0, 0] = (pred - scaler.min_[0]) / scaler.scale_[0]  # Scale the prediction
        new_seq[-1:] = new_row
        current_seq = new_seq
    
    return predictions

# Get realistic predictions
future_dates = [datetime.now() + timedelta(days=i) for i in range(1, 6)]
future_prices = predict_realistic_future()

print("\nRealistic Next 5 Day Predictions:")
for date, price in zip(future_dates, future_prices):
    print(f"{date.strftime('%Y-%m-%d')}: ${price:.2f}")

# Plot future predictions
plt.figure(figsize=(14, 6))
plt.plot(data.index[-30:], data['Close'][-30:], label='Historical Prices', color='blue')
plt.plot(future_dates, future_prices, 'ro-', label='Predicted Prices')
plt.title('XAU/USD Future Price Prediction')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.grid(True)
plt.show()

# %%
# Cell 9: Save Results
try:
    if TF_AVAILABLE:
        model.save('models/xauusd_model.keras')
    with open('models/latest_predictions.pkl', 'wb') as f:
        pickle.dump({'dates': future_dates, 'prices': future_prices}, f)
    data.to_csv('data/xauusd_latest.csv')
    print("\nResults saved successfully!")
except Exception as e:
    print(f"Error saving results: {e}")
